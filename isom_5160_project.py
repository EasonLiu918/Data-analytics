# -*- coding: utf-8 -*-
"""ISOM_5160_Project.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/199GnfCLins5QYu_Jsv0IFXvCVahBd4WB

# ğŸ§¾ ISOM 5160 Python Project â€“ Online Shoppers Intention Dataset

#1.ğŸ§¹ Data Cleaning
"""

import numpy as np
import pandas as pd

# To print multiple outputs for one cell
from IPython.core.interactiveshell import InteractiveShell
InteractiveShell.ast_node_interactivity = 'all'

df = pd.read_csv('online_shoppers_intention.csv')
df

# Show the number of rows and columns | è³‡æ–™ç­†æ•¸èˆ‡æ¬„ä½æ•¸
df.shape

# Show column names, data types, and non-null counts | è³‡æ–™å‹åˆ¥ + æ˜¯å¦æœ‰ç¼ºå€¼
df.info()

# Display the first 5 rows of the dataset | æ•¸å€¼æ¬„ä½çš„çµ±è¨ˆæ‘˜è¦
df.head()

# Check for missing values in each column | æŸ¥çœ‹ç¼ºå¤±å€¼æƒ…æ³
df.isnull().sum()

# Check how many duplicate rows exist in the dataset | æª¢æŸ¥è³‡æ–™ä¸­æœ‰å¤šå°‘åˆ—æ˜¯é‡è¤‡çš„
df.duplicated().sum()
# Display duplicated rows (excluding the first occurrence) | é¡¯ç¤ºæ‰€æœ‰é‡è¤‡åˆ—ï¼ˆé™¤äº†ç¬¬ä¸€æ¬¡å‡ºç¾çš„é‚£ä¸€ç­†ï¼‰
df[df.duplicated()]
# Remove duplicate rows | ç§»é™¤é‡è¤‡åˆ—
df = df.drop_duplicates()

"""#2.ğŸ§ª Data Transformation

## 2.1 Transforming format
"""

# Convert 'Month' and 'VisitorType' to categorical type | å°‡ 'Month' å’Œ 'VisitorType' æ¬„ä½è½‰ç‚ºé¡åˆ¥å‹
df['Month'] = df['Month'].astype('category')
df['VisitorType'] = df['VisitorType'].astype('category')

# Convert 'Weekend' and 'Revenue' to boolean type | å°‡ 'Weekend' and 'Revenue'æ¬„ä½è½‰ç‚ºå¸ƒæ—å‹ï¼ˆTrue/Falseï¼‰

df['Weekend'] = df['Weekend'].astype(bool)
df['Revenue'] = df['Revenue'].astype(bool)

# å†æ¬¡æª¢æŸ¥å‹åˆ¥
df.info()

"""## 2.2 Encoding"""

#âœ… One-hot encoding is used to convert categorical columns into binary vectors | One-hot ç·¨ç¢¼å¯ä»¥å°‡é¡åˆ¥å‹æ¬„ä½è½‰æ›æˆæ•¸å€¼æ¬„ä½ï¼Œè®“æ¨¡å‹èƒ½å¤ è™•ç†

# One-hot encode the 'Month' and 'VisitorType' columns | å° 'Month' å’Œ 'VisitorType' æ¬„ä½é€²è¡Œ One-Hot ç·¨ç¢¼
#df = pd.get_dummies(df, columns=['Month', 'VisitorType'], prefix=['Month', 'Visitor'])

# Show the new column names to verify | é¡¯ç¤ºæ–°çš„æ¬„ä½åç¨±ï¼Œç¢ºèªæ˜¯å¦æˆåŠŸå»ºç«‹ One-Hot æ¬„ä½
#df.columns

#df

"""## 2.3 Normalization"""

# âœ… Why normalize these columns? | ç‚ºä»€éº¼è¦æ­£è¦åŒ–é€™äº›æ¬„ä½ï¼Ÿ
# These numerical columns have large and varied scales | é€™äº›æ•¸å€¼æ¬„ä½çš„ç¯„åœå·®ç•°å¾ˆå¤§ï¼Œå°ºåº¦ä¸ä¸€ï¼Œ
normalize_cols = [
    'Administrative', 'Administrative_Duration',
    'Informational', 'Informational_Duration',
    'ProductRelated', 'ProductRelated_Duration',
    'PageValues'
]

df[normalize_cols] = df[normalize_cols].apply(
    lambda x: (x - x.min()) / (x.max() - x.min())
)

##  Display the summary statistics to verify normalization | é¡¯ç¤ºæ‘˜è¦çµ±è¨ˆå€¼ä¾†ç¢ºèªæ­£è¦åŒ–æˆåŠŸ
df[normalize_cols].describe()

"""#3.ğŸ“Š Data Summarization

## 3.1 Primary Statistics
"""

# Summary statistics for numerical columns | å°æ•¸å€¼æ¬„ä½åšçµ±è¨ˆæ‘˜è¦
df.describe()

# Summary statistics for boolean columns | å°å¸ƒæ—å€¼æ¬„ä½åšçµ±è¨ˆæ‘˜è¦ï¼ˆå¦‚: Weekend, Revenueï¼‰
df[['Weekend', 'Revenue']].describe()

# Why use value_counts? | ç‚ºä»€éº¼è¦ä½¿ç”¨ value_counts?
# Value counts is used to summarize categorical columns by showing the frequency of each unique value | å¯ä»¥å¹«åŠ©æˆ‘å€‘å¿«é€Ÿäº†è§£æ¯å€‹åˆ†é¡è³‡æ–™çš„åˆ†å¸ƒæƒ…æ³ï¼Œä¾‹å¦‚å“ªä¸€å€‹æœˆã€ç€è¦½å™¨æˆ–è¨ªå®¢é¡å‹å‡ºç¾æœ€å¤šã€‚

# Which columns are suitable? | å“ªäº›æ¬„ä½é©åˆä½¿ç”¨ value_counts?
# Suitable for categorical, boolean, and low-cardinality integer columns | é©åˆé¡åˆ¥å‹ï¼ˆå¦‚æœˆä»½ã€è¨ªå®¢é¡å‹ï¼‰ã€å¸ƒæ—å‹ï¼ˆå¦‚Weekendï¼‰ã€ä»¥åŠç¨®é¡ä¸å¤šçš„æ•´æ•¸æ¬„ä½ï¼ˆå¦‚ç€è¦½å™¨ã€ç³»çµ±ã€åœ°å€ç­‰ï¼‰

# Define the natural order of months that appear in the dataset | å®šç¾©è³‡æ–™é›†ä¸­å‡ºç¾éçš„æœˆä»½ï¼Œä¸¦ä¾ç…§è‡ªç„¶æœˆä»½é †åºæ’åˆ—
month_order = ['Feb', 'Mar', 'May', 'June', 'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec']

#Convert 'Month' column into an ordered categorical type | å°‡ 'Month' æ¬„ä½è½‰æ›æˆæœ‰é †åºçš„é¡åˆ¥å‹
df['Month'] = pd.Categorical(df['Month'], categories=month_order, ordered=True)

# ğŸ‘‰ Count month distribution | è¨ˆç®—æ¯å€‹æœˆä»½çš„å‡ºç¾æ¬¡æ•¸
df['Month'].value_counts().sort_index()

# ğŸ‘‰ Count visitor type distribution | è¨ˆç®—è¨ªå®¢é¡å‹çš„å‡ºç¾æ¬¡æ•¸
df['VisitorType'].value_counts().sort_index()

# Count boolean values (True/False) | å¸ƒæ—å‹æ¬„ä½çµ±è¨ˆï¼ˆTrue/False å‡ºç¾æ¬¡æ•¸ï¼‰
df['Weekend'].value_counts().sort_index()
df['Revenue'].value_counts().sort_index()

# Count low-cardinality integer columns representing categorical data | å…¶ä»–åˆ†é¡å‹æ¬„ä½çµ±è¨ˆï¼ˆæ•´æ•¸ä½†ä»£è¡¨åˆ†é¡ï¼‰
df['Region'].value_counts()
df['TrafficType'].value_counts()
df['Browser'].value_counts()
df['OperatingSystems'].value_counts()

"""## 3.2 Pivot Table & GroupBy"""

# Total number of purchases per month | æ¯æœˆçš„æˆäº¤æ¬¡æ•¸
df.groupby('Month')['Revenue'].sum().sort_index()

# Conversion rate per month | æ¯æœˆçš„æˆäº¤ç‡ï¼ˆæˆäº¤æ•¸ / è©²æœˆç¸½æ•¸ï¼‰
df.groupby('Month')['Revenue'].mean().sort_index()

# Total number of purchases per visitor type | æ¯ç¨®è¨ªå®¢é¡å‹çš„æˆäº¤æ¬¡æ•¸
df.groupby('VisitorType')['Revenue'].sum()

# Conversion rate per operating system | æ¯ç¨®ä½œæ¥­ç³»çµ±çš„æˆäº¤ç‡ï¼ˆæˆäº¤æ•¸ / è©²ç³»çµ±ç¸½æ•¸ï¼‰
df.groupby('OperatingSystems')['Revenue'].mean()

# Total number of purchases per browser type | æ¯ç¨®ç€è¦½å™¨çš„æˆäº¤æ¬¡æ•¸
df.groupby('Browser')['Revenue'].sum()

# Conversion rate per region | æ¯å€‹åœ°å€çš„æˆäº¤ç‡ï¼ˆæˆäº¤æ•¸ / åœ°å€ç¸½æ•¸ï¼‰
df.groupby('Region')['Revenue'].mean()

# Pivot table: total purchases by Month and VisitorType | äº¤å‰åˆ†æã€Œæœˆä»½ã€èˆ‡ã€Œè¨ªå®¢é¡å‹ã€çš„æˆäº¤æ¬¡æ•¸
df.pivot_table(values='Revenue', index='Month', columns='VisitorType', aggfunc='sum', fill_value=0)

# Pivot table: conversion rate by Month and VisitorType | äº¤å‰åˆ†æã€Œæœˆä»½ã€èˆ‡ã€Œè¨ªå®¢é¡å‹ã€çš„æˆäº¤ç‡
df.pivot_table(values='Revenue', index='Month', columns='VisitorType', aggfunc='mean', fill_value=0)

# Pivot table: conversion rate by OperatingSystem and Browser | ä½œæ¥­ç³»çµ± Ã— ç€è¦½å™¨çš„æˆäº¤ç‡åˆ†æ
df.pivot_table(values='Revenue', index='OperatingSystems', columns='Browser', aggfunc='mean', fill_value=0)

# Pivot table: number of purchases by Region and VisitorType | åœ°å€ Ã— è¨ªå®¢é¡å‹ çš„æˆäº¤æ¬¡æ•¸
df.pivot_table(values='Revenue', index='Region', columns='VisitorType', aggfunc='sum', fill_value=0)

# Pivot table: purchases by Month and Weekend | æ¯æœˆé€±æœ«èˆ‡å¦çš„æˆäº¤æ¬¡æ•¸åˆ†æ
df.pivot_table(values='Revenue', index='Month', columns='Weekend', aggfunc='sum', fill_value=0)

# Pivot table: bounce and exit rates by month | æ¯æœˆçš„è·³å‡ºç‡èˆ‡é€€å‡ºç‡å¹³å‡
df.pivot_table(values=['BounceRates', 'ExitRates'], index='Month', aggfunc='mean')

"""#4.ğŸ“ˆExploratory Analysis

##4.1 Monthly Trend Analysis

###4.1.1 Monthly Conversion Trend | æ¯æœˆæˆäº¤ç‡è¶¨å‹¢åœ–
"""

import matplotlib.pyplot as plt

#Compute average conversion rate per month | è¨ˆç®—æ¯æœˆå¹³å‡æˆäº¤ç‡
monthly_conversion = df.groupby('Month')['Revenue'].mean().sort_index()

fig, ax = plt.subplots(figsize=(10, 5))

ax.plot(monthly_conversion.index, monthly_conversion.values, marker='o', linestyle='-', color='tab:blue')

#Add labels, title, and grid | æ·»åŠ æ¨™ç±¤ã€æ¨™é¡Œèˆ‡ç¶²æ ¼
ax.set_title('Monthly Conversion Trend', fontsize=14)
ax.set_xlabel('Month')
ax.set_ylabel('Conversion Rate')
ax.grid(True)

#Annotate each data point | é¡¯ç¤ºæ•¸å€¼æ¨™ç±¤
for i in range(len(monthly_conversion)):
    month = monthly_conversion.index[i]
    value = monthly_conversion.values[i]
    ax.text(month, value + 0.005, f'{value:.3f}')

plt.tight_layout()
plt.show()

"""###4.1.2 Monthly Revenue Volume ï½œ æ¯æœˆæˆäº¤æ¬¡æ•¸æ¢å½¢åœ–"""

#Compute total number of purchases per month ï½œ è¨ˆç®—æ¯æœˆæˆäº¤æ¬¡æ•¸ï¼ˆæˆäº¤ = Revenue ç‚º Trueï¼‰
monthly_volume = df.groupby('Month')['Revenue'].sum().sort_index()

fig, ax = plt.subplots(figsize=(10, 5))

ax.bar(monthly_volume.index, monthly_volume.values, color='tab:orange')

#Add title, labels, and grid ï½œ æ·»åŠ æ¨™é¡Œã€æ¨™ç±¤èˆ‡ç¶²æ ¼ç·š
ax.set_title('Monthly Revenue Volume', fontsize=14)
ax.set_xlabel('Month')
ax.set_ylabel('Number of Purchases')
ax.grid(True, axis='y')

#Annotate each bar ï½œ é¡¯ç¤ºæˆäº¤æ¬¡æ•¸æ•¸å€¼æ¨™ç±¤
for i in range(len(monthly_volume)):
    month = monthly_volume.index[i]
    value = monthly_volume.values[i]
    ax.text(month, value + 10, f'{int(value)}', ha='center')

plt.tight_layout()
plt.show()

"""###4.1.3 Monthly Bounce & Exit Rates | æ¯æœˆè·³å‡ºç‡èˆ‡é›¢é–‹ç‡è¶¨å‹¢åœ–"""

# Step 1: Compute monthly averages | è¨ˆç®—æ¯æœˆå¹³å‡çš„è·³å‡ºç‡èˆ‡é›¢é–‹ç‡
bounce_exit = df.pivot_table(values=['BounceRates', 'ExitRates'], index='Month', aggfunc='mean').sort_index()

# Step 2: Create figure and axes | å»ºç«‹åœ–å½¢èˆ‡åº§æ¨™è»¸
fig, ax = plt.subplots(figsize=(10, 5))

# Step 3: Plot the two lines | ç¹ªè£½å…©æ¢æŠ˜ç·šåœ–ï¼šè·³å‡ºç‡èˆ‡é›¢é–‹ç‡
ax.plot(bounce_exit.index, bounce_exit['BounceRates'], marker='o', linestyle='-', color='tab:red', label='Bounce Rate')
ax.plot(bounce_exit.index, bounce_exit['ExitRates'], marker='s', linestyle='--', color='tab:blue', label='Exit Rate')

# Step 4: Add labels, grid, and legend | åŠ å…¥æ¨™ç±¤ã€ç¶²æ ¼èˆ‡åœ–ä¾‹
ax.set_title('Monthly Bounce and Exit Rates', fontsize=14)
ax.set_xlabel('Month')
ax.set_ylabel('Rate')
ax.grid(True)
ax.legend()

# Step 5: Annotate each value | é¡¯ç¤ºæ•¸å€¼æ¨™ç±¤
for i in range(len(bounce_exit)):
    ax.text(bounce_exit.index[i], bounce_exit['BounceRates'][i] + 0.002, f"{bounce_exit['BounceRates'][i]:.3f}", color='tab:red')
    ax.text(bounce_exit.index[i], bounce_exit['ExitRates'][i] + 0.001, f"{bounce_exit['ExitRates'][i]:.3f}", color='tab:blue')

plt.tight_layout()
plt.show()

"""##4.2 Category-wise Analysisï¼ˆåˆ†é¡è®Šæ•¸åˆ†æï¼‰

###4.2.1 Conversion Rate by Visitor Type
"""

# Group by visitor type and calculate average conversion rate | è¨ˆç®—æ¯ç¨®è¨ªå®¢é¡å‹çš„å¹³å‡æˆäº¤ç‡
visitor_conversion = df.groupby('VisitorType')['Revenue'].mean()

fig, ax = plt.subplots(figsize=(8, 5))

# Define custom colors for each bar | è‡ªè¨‚æ¯æ ¹æŸ±å­çš„é¡è‰²
colors = ['skyblue', 'lightgreen', 'salmon']

ax.bar(visitor_conversion.index, visitor_conversion.values, color=colors)

ax.set_title('Conversion Rate by Visitor Type', fontsize=14, color='darkblue')
ax.set_xlabel('Visitor Type')
ax.set_ylabel('Conversion Rate')
ax.set_ylim(0, visitor_conversion.max() + 0.05)  # èª¿æ•´ y è»¸ä¸Šé™
ax.grid(True, axis='y', linestyle='--', alpha=0.6)

# Show value labels on each bar | æ¯æ ¹æŸ±å­é¡¯ç¤ºæ•¸å€¼
for i in range(len(visitor_conversion)):
    ax.text(i, visitor_conversion.values[i] + 0.01,
            f'{visitor_conversion.values[i]:.2f}',
            ha='center', color='black')

plt.tight_layout()
plt.show()

"""###4.2.2 Conversion Rate by Operation System"""

# Calculate conversion rate by Operating System | è¨ˆç®—æ¯ç¨®ä½œæ¥­ç³»çµ±çš„æˆäº¤ç‡
df['OS_Label'] = df['OperatingSystems'].map(os_map)  # Map OS codes to names | å°‡ä½œæ¥­ç³»çµ±ä»£ç¢¼å°æ‡‰ç‚ºåç¨±
os_conv = df.groupby('OS_Label')['Revenue'].mean().sort_values()  # Group and compute mean conversion rate | åˆ†çµ„ä¸¦è¨ˆç®—å¹³å‡æˆäº¤ç‡

fig, ax = plt.subplots(figsize=(8, 5))
bars = ax.bar(os_conv.index, os_conv.values, color='lightblue')
ax.set_title('Conversion Rate by Operating System')
ax.set_xlabel('Operation System')
ax.set_ylabel('Conversion Rate')
ax.set_ylim(0, os_conv.values.max() + 0.05)  # Set y-limit with buffer | è¨­å®š y è»¸ç¯„åœ

# Add labels above bars | åœ¨é•·æ¢ä¸Šæ–¹åŠ ä¸Šæ•¸å€¼æ¨™ç±¤
for i in range(len(os_conv)):
    ax.text(i, os_conv.values[i] + 0.01, f"{os_conv.values[i]:.3f}", ha='center')

plt.tight_layout()
plt.show()

"""### 4.2.3 Conversion Rate by Browser"""

# ğŸ§­ Map browser codes to names ï½œå°‡ç€è¦½å™¨ä»£ç¢¼è½‰æˆåç¨±
df['Browser_Label'] = df['Browser'].map(browser_map)

# ğŸ“ˆ Compute conversion rate by browser ï½œè¨ˆç®—æ¯ç¨®ç€è¦½å™¨çš„å¹³å‡è½‰æ›ç‡
browser_conv = df.groupby('Browser_Label')['Revenue'].mean().sort_values()

fig, ax = plt.subplots(figsize=(10, 5))
bars = ax.bar(browser_conv.index, browser_conv.values, color='lightcoral')

ax.set_title('Conversion Rate by Browser', fontsize=14, color='darkblue')
ax.set_xlabel('Browser')
ax.set_ylabel('Conversion Rate')
ax.set_ylim(0, browser_conv.max() + 0.05)

for i, bar in enumerate(bars):
    height = bar.get_height()
    ax.text(bar.get_x() + bar.get_width() / 2,
            height + 0.01,
            f'{height:.3f}',
            ha='center', fontsize=10)

plt.tight_layout()
plt.show()

"""##4.3 Correlation Analysis

### 4.3.1 Remove Outlier
"""

# Select a numeric column for boxplot | é¸æ“‡æ•¸å€¼å‹æ¬„ä½ä¾†ç•« boxplot
roomprice = df['ExitRates']

# Draw a boxplot to visualize outliers | ç•«å‡º boxplot ä¾†è§€å¯Ÿé›¢ç¾¤å€¼
fig, ax = plt.subplots(figsize=(10, 4))
ax.boxplot(roomprice, vert=False, showfliers=True, whis=1.5, labels=["ExitRates"])
ax.set_title('Boxplot of ExitRates', fontsize=14)
plt.show()

# Calculate IQR and bounds for outlier detection | è¨ˆç®— IQR åŠåˆ¤å®šé›¢ç¾¤å€¼çš„ä¸Šä¸‹ç•Œ
q1 = roomprice.quantile(0.25)
q3 = roomprice.quantile(0.75)
iqr = q3 - q1

left_end = q1 - 1.5 * iqr
right_end = q3 + 1.5 * iqr

print(f"The Interquartile Range (IQR) is {iqr:.2f}")
print(f"Outlier range: less than {left_end:.2f} or greater than {right_end:.2f}")

# Identify outliers | æ‰¾å‡ºé›¢ç¾¤å€¼
outliers = df[(roomprice < left_end) | (roomprice > right_end)]
print(f"Number of outliers: {len(outliers)} ({len(outliers)/len(roomprice):.1%})")

# Select a numeric column for boxplot | é¸æ“‡æ•¸å€¼å‹æ¬„ä½ä¾†ç•« boxplot
roomprice = df['ExitRates']

# Calculate IQR and bounds for outlier detection | è¨ˆç®—IQR åŠåˆ¤å®šé›¢ç¾¤å€¼çš„ä¸Šä¸‹ç•Œ
q1 = roomprice.quantile(0.25)
q3 = roomprice.quantile(0.75)
iqr = q3 - q1

# ä½¿ç”¨ whisker = 1.5 ä¾†ç•Œå®šé›¢ç¾¤å€¼ç¯„åœ
whisker = 1.5
left_end = q1 - whisker * iqr
right_end = q3 + whisker * iqr

# Calculate the percentage of the outliers | è¨ˆç®—é›¢ç¾¤å€¼çš„æ¯”ä¾‹
outliers = df[(roomprice < left_end) | (roomprice > right_end)]
print(f"The Interquartile Range (IQR) is {iqr:.2f}")
print(f"Outlier range: less than {left_end:.2f} or greater than {right_end:.2f}")
print(f"Number of outliers: {len(outliers)} ({len(outliers)/len(roomprice):.1%})")

# Remove the outliers outside the specified range | ç§»é™¤é›¢ç¾¤å€¼
df = df[(roomprice >= left_end) & (roomprice <= right_end)]

# Print the shape of the DataFrame after removing outliers | åˆªé™¤å¾Œå°å‡ºè³‡æ–™æ•¸é‡
print(df.shape)

# Select the cleaned numeric column for boxplot ï½œ é¸æ“‡æ¸…ç†å¾Œçš„æ•¸å€¼æ¬„ä½ä¾†ç•« boxplot
roomprice = df['ExitRates']

# Draw a boxplot to visualize outliers ï½œ ç•«å‡º boxplot ä¾†ç¢ºèªæ˜¯å¦é‚„æœ‰é›¢ç¾¤å€¼
fig, ax = plt.subplots(figsize=(10, 4))
ax.boxplot(roomprice, vert=False, showfliers=True, whis=1.5, labels=["ExitRates"])
ax.set_title('Boxplot of ExitRates (after removing outliers)', fontsize=14)
plt.show()

"""###4.3.2 Correlation with Revenue"""

# Import necessary libraries | åŒ¯å…¥å¿…è¦çš„å‡½å¼åº«
import matplotlib.pyplot as plt
import seaborn as sns

# Compute correlation matrix using numeric columns only | è¨ˆç®—æ•¸å€¼å‹æ¬„ä½çš„ç›¸é—œä¿‚æ•¸çŸ©é™£
corr = df.corr(numeric_only=True)

# Create a heatmap to visualize the correlation matrix | å»ºç«‹ç†±åŠ›åœ–ä¾†è¦–è¦ºåŒ–ç›¸é—œæ€§çŸ©é™£
plt.figure(figsize=(13, 10))

# Draw the heatmap with color scale from -1 to 1 | ç•«å‡ºç›¸é—œæ€§ç†±åŠ›åœ–ï¼Œç¯„åœå¾ -1 åˆ° 1
ax = sns.heatmap(corr, vmin=-1, vmax=1, annot=True, center=0,
                 cmap=sns.diverging_palette(30, 240, n=200))

# Rotate x-axis labels for better readability | æ—‹è½‰ x è»¸æ¨™ç±¤ä»¥æé«˜å¯è®€æ€§
ax.set_xticklabels(ax.get_xticklabels(), rotation=45, horizontalalignment='right')

# Set title | è¨­ç½®æ¨™é¡Œ
plt.title('Correlation Matrix of Numeric Features', fontsize=14)

plt.tight_layout()
plt.show()

# Select correlations with Revenue only | é¸å–å’Œ Revenue çš„ç›¸é—œä¿‚æ•¸
revenue_corr = corr['Revenue'].drop('Revenue').sort_values(key=abs, ascending=False)

# Display top 5 features | é¡¯ç¤ºå‰5å€‹ç‰¹å¾µ
print(revenue_corr.head(5))

# Plot bar chart for top correlations | ç¹ªè£½èˆ‡ Revenue æœ€é«˜ç›¸é—œæ€§çš„ç‰¹å¾µ
plt.figure(figsize=(8, 5))
sns.barplot(x=revenue_corr.head(5).values, y=revenue_corr.head(5).index, palette='coolwarm')

plt.title('Top 5 Features Correlated with Revenue', fontsize=14)
plt.xlabel('Correlation Coefficient')
plt.ylabel('Feature')
plt.grid(axis='x', linestyle='--', alpha=0.7)
plt.tight_layout()
plt.show()

"""### 4.3.3 Correlation Matrix


"""

# ğŸ“Š Compute the correlation matrix | è¨ˆç®—ç›¸é—œä¿‚æ•¸çŸ©é™£
corr_matrix = df.corr(numeric_only=True)

# ğŸ”„ Flatten the correlation matrix into feature pairs | å°‡ç›¸é—œä¿‚æ•¸çŸ©é™£è½‰æ›æˆè®Šæ•¸å°åˆ—è¡¨
corr_pairs = corr_matrix.unstack().reset_index()
corr_pairs.columns = ['Feature1', 'Feature2', 'Correlation']

# Remove self-correlation pairs (correlation = 1.0) | ç§»é™¤è‡ªå·±è·Ÿè‡ªå·±æ¯”è¼ƒçš„æƒ…æ³
corr_pairs = corr_pairs[corr_pairs['Feature1'] != corr_pairs['Feature2']]

# Drop duplicate pairs (A-B and B-A are the same) | ç§»é™¤é‡è¤‡çš„è®Šæ•¸å°ï¼ˆA-B å’Œ B-A è¦–ç‚ºä¸€æ¨£ï¼‰
corr_pairs['Set'] = corr_pairs.apply(lambda row: frozenset([row['Feature1'], row['Feature2']]), axis=1)
corr_pairs = corr_pairs.drop_duplicates(subset='Set').drop(columns='Set')

# Sort to get Top 5 positive and negative feature pairs | æ’åºä¸¦åˆ†åˆ¥å–å‡ºTop 5æ­£ç›¸é—œå’Œè² ç›¸é—œè®Šæ•¸å°
top5_positive = corr_pairs.sort_values(by='Correlation', ascending=False).head(5)
top5_negative = corr_pairs.sort_values(by='Correlation', ascending=True).head(5)

# Display the results | é¡¯ç¤ºçµæœ
print("Top 5 Positive Correlated Feature Pairs")
print(top5_positive)

print("\nTop 5 Negative Correlated Feature Pairs")
print(top5_negative)

# ğŸ“Š Visualize selected feature pairs with Pair Plot | ä½¿ç”¨Pair Plotå¯è¦–åŒ–ç¯©é¸çš„è®Šæ•¸å°

import seaborn as sns
import matplotlib.pyplot as plt

# Select important features | é¸æ“‡é‡è¦çš„ç‰¹å¾µ
selected_features = list(set(top5_positive['Feature1'].tolist() +
                             top5_positive['Feature2'].tolist() +
                             top5_negative['Feature1'].tolist() +
                             top5_negative['Feature2'].tolist()))

# Subset the dataframe | æå–é€™äº›ç‰¹å¾µçš„å­é›†
subset_df = df[selected_features]

# Create pair plot | ç•«å‡ºpair plot
sns.pairplot(subset_df, corner=True)
plt.suptitle('Pair Plot of Top Correlated Features', y=1.02, fontsize=16)
plt.tight_layout()
plt.show()